{"version":3,"file":"index.4fd3c3633a65df6ec748.hot-update.js","mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AAEA;AAEA;AACA;AACA;;AACA;AAEA;AACA;AACA;;AACA,MAAMK,WAAW,GAAG,EAApB;AAEA,MAAMC,YAAY,GAAGH,iEAAa,EAAlC;;AAEA,MAAMI,OAAO,GAAG,CAAEC,GAAF,EAAOC,GAAP,EAAYC,IAAZ,KAAsB;AACrC,MAAKD,GAAG,KAAK,YAAR,IAAwBD,GAAG,CAAEC,GAAF,CAAH,CAAYC,IAAZ,EAAmBC,QAA3C,IAAuDD,IAAI,CAAC,CAAD,CAAJ,KAAYA,IAAI,CAAC,CAAD,CAAJ,CAAQE,WAAR,EAAxE,EAAgG;AAC/F,WAAO,WAAP;AACA;;AAED,SAAO,OAAOJ,GAAG,CAAEC,GAAF,CAAH,CAAYC,IAAZ,CAAd;AACA,CAND;;AASA,MAAMG,UAAU,GAAKJ,GAAF,IAAW;AAC1BK,SAAO,CAACC,GAAR,CAAYN,GAAZ,EAD0B,CAE1B;AACA;AACA;;AAEH,SAAQ,+EAA+EO,MAAQ,EAA/F;AACA,CAPD;;AASA,MAAMC,YAAY,GAAKC,WAAF,IAAmB;AACvC,QAAMC,CAAC,GAAGD,WAAW,CAACE,KAAZ,CAAmB,GAAnB,CAAV,CADuC,CAGvC;;AACA,MAAKD,CAAC,CAAE,CAAF,CAAN,EAAc;AACb,WAAO,MAAMA,CAAC,CAAE,CAAF,CAAd;AACA;;AAED,SAAO,EAAP;AACA,CATD;;AAYA,MAAME,OAAO,GAAKb,GAAF,IAAW;AAC1B,MAAIc,GAAG,GAAG,EAAV;;AAEA,OAAM,IAAIb,GAAV,IAAiBD,GAAjB,EAAuB;AACtB,SAAM,IAAIE,IAAV,IAAkBF,GAAG,CAAEC,GAAF,CAArB,EAA+B;AAC9B,UAAKD,GAAG,CAAEC,GAAF,CAAH,CAAYC,IAAZ,CAAL,EAA0B;AACzBY,WAAG,CAACC,IAAJ,CAAU;AACTC,cAAI,EAAG,GAAGf,GAAK,IAAIC,IAAM,EADhB;AAETe,cAAI,EAAElB,OAAO,CAAEC,GAAF,EAAOC,GAAP,EAAYC,IAAZ,CAFJ;AAGMgB,iBAAO,EAAGb,UAAU,CAACJ,GAAD;AAH1B,SAAV;AAKA;AACD;AACD;;AACD,SAAOa,GAAP;AACA,CAfD;;AAkBO,SAASK,eAAT,OAAyC;AAAA;;AAAA,MAAf;AAAEC;AAAF,GAAe;AAC/C,QAAM,CAAEC,MAAF,EAAUC,SAAV,IAAwB5B,4DAAQ,CAAE,QAAF,CAAtC;AACA,QAAM,CAAEgB,WAAF,EAAea,cAAf,IAAkC7B,4DAAQ,CAAE,IAAF,CAAhD;AACA,QAAM,CAAE8B,cAAF,EAAkBC,iBAAlB,IAAwC/B,4DAAQ,CAAE,IAAF,CAAtD;AACA,MAAIgC,OAAO,GAAGb,OAAO,CAAEc,EAAF,CAArB;AAEA,QAAMC,MAAM,GAAG,EAAf;;AAEA,OAAM,IAAIC,CAAC,GAAG,CAAd,EAAiBA,CAAC,GAAGC,MAAM,CAACC,IAAP,CAAaJ,EAAb,EAAkBK,MAAvC,EAA+CH,CAAC,EAAhD,EAAqD;AACpD,UAAMI,GAAG,GAAGH,MAAM,CAACC,IAAP,CAAaJ,EAAb,EAAmBE,CAAnB,CAAZ;;AACA,QAAKF,EAAE,CAAEM,GAAF,CAAF,CAAUC,KAAf,EAAuB;AACtBN,YAAM,CAAEK,GAAF,CAAN,GAAgBN,EAAE,CAAEM,GAAF,CAAlB;AACA;AACD;;AACD,QAAME,UAAU,GAAGL,MAAM,CAACC,IAAP,CAAaH,MAAb,EAAsBQ,GAAtB,CAChBP,CAAF,IAASD,MAAM,CAAEC,CAAF,CAAN,CAAYK,KAAZ,CAAkBG,IADT,CAAnB,CAd+C,CAkB/C;;AACA,OAAM,IAAIC,CAAC,GAAG,CAAd,EAAiBA,CAAC,GAAGH,UAAU,CAACH,MAAhC,EAAwCM,CAAC,EAAzC,EAA8C;AAC7C,UAAMJ,KAAK,GAAGC,UAAU,CAAEG,CAAF,CAAxB;AACAZ,WAAO,GAAGA,OAAO,CAACa,MAAR,CACT1B,OAAO,CAAE;AACR,OAAG,gBAAgBqB,KAAO,IAA1B,GAAiCP,EAAE,CAACa,IAAH,CAAQC,MAAR,CAAgBP,KAAhB;AADzB,KAAF,CADE,CAAV;AAKA,GA1B8C,CA4B/C;;;AACA,OAAM,IAAII,CAAC,GAAG,CAAd,EAAiBA,CAAC,GAAGH,UAAU,CAACH,MAAhC,EAAwCM,CAAC,EAAzC,EAA8C;AAC7C,UAAMJ,KAAK,GAAGC,UAAU,CAAEG,CAAF,CAAxB;AACAZ,WAAO,GAAGA,OAAO,CAACa,MAAR,CACT1B,OAAO,CAAE;AACR,OAAG,kBAAkBqB,KAAO,IAA5B,GAAmCP,EAAE,CAACa,IAAH,CAAQE,QAAR,CAAkBR,KAAlB;AAD3B,KAAF,CADE,CAAV;AAKA;;AAED,QAAM1C,MAAM,GAAKmD,OAAF,IAAe;AAC7B,UAAMC,OAAO,GAAGnD,kDAAU,CAAEkD,OAAF,EAAWjB,OAAX,EAAoB;AAC7CmB,gBAAU,EAAE,IADiC;AAE7CC,iBAAW,EAAI9C,GAAF,IAAWA,GAAG,CAACgB;AAFiB,KAApB,CAA1B;AAIA,WAAO4B,OAAO,CAACG,MAAR,CAAgB,CAAhB,EAAmBlD,WAAnB,CAAP;AACA,GAND;;AAQA,SACC,kEAAC,YAAD,CAAc,QAAd;AACC,SAAK,EAAG;AACPwB,YADO;AAEPC,eAFO;AAGPZ,iBAHO;AAIPa,oBAJO;AAKPC,oBALO;AAMPC,uBANO;AAOPG,YAPO;AAQPpC;AARO;AADT,KAYG4B,QAZH,CADD;AAgBA;;GA9DeD;;KAAAA;AAgET,SAAS6B,UAAT,GAAsB;AAAA;;AAC5B,QAAMC,OAAO,GAAGrD,8DAAU,CAAEE,YAAF,CAA1B;;AAEA,MAAKmD,OAAO,KAAKC,SAAjB,EAA6B;AAC5B,UAAM,IAAIC,KAAJ,CAAW,wCAAX,CAAN;AACA;;AAED,SAAOF,OAAP;AACA;;IAReD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClIhB,cAAc,mBAAO,CAAC,sDAAS;AAC/B,qBAAqB,+FAA+B;AACpD,oBAAoB,6FAA8B;;AAElD,oBAAoB,mBAAO,CAAC,0DAAc;AAC1C,eAAe,mFAA2B;;AAE1C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,sBAAsB,WAAW;AACjC;AACA;;AAEA;AACA;AACA;AACA;;AAEA,oBAAoB,uBAAuB,iBAAiB;AAC5D;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,uBAAuB,iBAAiB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,kBAAkB,gBAAgB;AAClC;AACA;AACA;AACA;AACA;;AAEA,uBAAuB,oBAAoB;AAC3C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;;;;;;;;;AC7IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA,IAAI,KAA4D;AAChE;AACA,UAAU,CAeM;AAChB,CAAC;AACD;AACA,iBAAiB,qBAAM,mBAAmB,qBAAM;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,oBAAoB;AACxD;AACA,KAAK;AACL,mCAAmC,EAAE,oBAAoB,EAAE,sBAAsB,EAAE;AACnF;AACA;AACA;AACA;AACA,iCAAiC,oBAAoB;AACrD;AACA;AACA,sCAAsC;AACtC,6DAA6D,+BAA+B;AAC5F,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,eAAe;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,iBAAiB,QAAQ;AACzB;AACA,4CAA4C;AAC5C,wCAAwC;AACxC;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA,4CAA4C,OAAO;AACnD;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,SAAS;AACxB,iBAAiB,QAAQ;AACzB;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,iBAAiB,QAAQ;AACzB;AACA,8BAA8B;AAC9B;AACA;AACA,yBAAyB;AACzB;AACA,6BAA6B;AAC7B,6BAA6B;AAC7B;AACA;AACA,eAAe,SAAS;AACxB,iBAAiB,QAAQ;AACzB;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,QAAQ;AACzB;AACA,qCAAqC;AACrC;AACA;AACA;AACA,iEAAiE,EAAE,wBAAwB,EAAE;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,iBAAiB,QAAQ;AACzB;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,eAAe;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,iBAAiB,QAAQ;AACzB;AACA,4CAA4C;AAC5C,wCAAwC;AACxC;AACA;AACA;AACA,yBAAyB;AACzB,yBAAyB,yCAAyC,yBAAyB;AAC3F;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA,yBAAyB;AACzB;AACA,6BAA6B;AAC7B,6BAA6B;AAC7B,gCAAgC,mDAAmD,+BAA+B;AAClH;AACA;AACA,eAAe,QAAQ;AACvB,iBAAiB,QAAQ;AACzB;AACA,kCAAkC;AAClC;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA,mDAAmD,IAAI;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C,yCAAyC,sBAAsB;AAC/D,8CAA8C,+BAA+B;AAC7E,0CAA0C,4BAA4B;AACtE,0CAA0C,4BAA4B;AACtE,2CAA2C,4BAA4B;AACvE;AACA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C,8CAA8C,uCAAuC;AACrF,0CAA0C,oCAAoC;AAC9E,0CAA0C,oCAAoC;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACxC;AACA,gDAAgD,wCAAwC;AACxF;AACA,CAAC;;;;;;;;;;;AC9TD;AACA;;AAEA;AACA,sCAAsC;AACtC,sCAAsC;AACtC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B,4BAA4B;AAC5B;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,cAAc,WAAW;AACzB,cAAc,gBAAgB;;AAE9B;AACA,2BAA2B,QAAQ;AACnC;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,cAAc,OAAO;;AAErB;AACA;AACA;;AAEA,cAAc,QAAQ;AACtB,cAAc,SAAS;AACvB,cAAc,OAAO;AACrB,cAAc,SAAS;;AAEvB;AACA,cAAc,OAAO;;AAErB;;AAEA,cAAc,QAAQ;AACtB;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,cAAc,QAAQ;;AAEtB;AACA,cAAc,SAAS;;AAEvB;;AAEA;AACA,uBAAuB,QAAQ;AAC/B;AACA;AACA;;AAEA;AACA,cAAc,SAAS;AACvB;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,cAAc,QAAQ;;AAEtB;AACA,cAAc,WAAW;AACzB;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,gBAAgB,mBAAmB;AACnC;;AAEA;AACA;AACA;AACA;AACA,+CAA+C,QAAQ;AACvD;AACA;AACA;AACA;AACA;AACA,+CAA+C,QAAQ;AACvD;AACA;AACA;AACA;AACA;AACA,gDAAgD,QAAQ;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;;AAEA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA,qBAAqB,mBAAmB;AACxC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA,mBAAmB,GAAG;AACtB;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,IAAI;;AAEJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;;;;;;;;;;ACtXA,gBAAgB,mBAAO,CAAC,0DAAc;AACtC,QAAQ,WAAW,EAAE,mBAAO,CAAC,mDAAQ;;AAErC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,4CAA4C;;AAE5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA,MAAM;AACN;AACA,SAAS,0EAA0E;AACnF;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;;;;;;;;;ACvIA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,kBAAkB,SAAS;AAC3B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACxBkC;;AAElC;AACA,2CAA2C,QAAQ;AACnD;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,iEAAiE;;;AAGjE;AACA,0EAA0E;;AAE1E;AACA;AACA;AACA;;AAEA,yBAAyB,0CAAK;AAC9B;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA,IAAI;;;AAGJ;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,EAAE;;;AAGF;AACA;AACA;AACA;AACA;AACA,EAAE;;;AAGF;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,gCAAgC,oBAAoB;AACpD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,EAAE;;;AAGF;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,kBAAkB,YAAY;AAC9B;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,kBAAkB,cAAc;AAChC;AACA;AACA;;AAEA,kBAAkB,iBAAiB;AACnC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,kBAAkB,cAAc;AAChC;AACA;AACA;;AAEA;AACA,EAAE;;;AAGF;AACA;AACA;AACA;AACA;AACA,yBAAyB;;AAEzB,4CAA4C;;AAE5C,2CAA2C;;AAE3C;AACA,EAAE;AACF;;;AAGA;AACA,kBAAkB,iBAAiB;AACnC;AACA;AACA,EAAE;AACF;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;;;AAGA;AACA;AACA;;AAEA,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;AACA,WAAW;;AAEX,2BAA2B;;AAE3B,8CAA8C;;AAE9C,6CAA6C;;AAE7C;AACA;AACA;AACA,EAAE;AACF;;;AAGA;AACA;;AAEA,kBAAkB,mBAAmB;AACrC,4BAA4B;;AAE5B;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA,MAAM;;;AAGN,8DAA8D;;AAE9D;AACA;;AAEA;AACA,EAAE;AACF;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,EAAE;;;AAGF;AACA;AACA;;AAEA;AACA;AACA,IAAI;;;AAGJ;;AAEA;AACA;AACA,IAAI;;;AAGJ;;AAEA;AACA;AACA,IAAI;;;AAGJ;;AAEA;AACA;AACA,IAAI;;;AAGJ;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,+CAA+C,OAAO;AACtD;AACA,EAAE;;;AAGF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;;AAEA,mDAAmD;;;AAGnD;AACA;AACA,2BAA2B;;AAE3B,0DAA0D;AAC1D;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,EAAE;;;AAGF;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,yBAAyB;;AAEzB,kDAAkD;;AAElD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAM;;;AAGN;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,MAAM;;;AAGN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,EAAE;AACF;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA,EAAE;;;AAGF;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,kBAAkB,8BAA8B;AAChD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ,EAAE;;AAEF;AACA,cAAc;AACd;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA,EAAE;AACF;;AAEA;AACA;AACA,mCAAmC;AACnC;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,8BAA8B;AAC9B;AACA;;AAEA;;AAE6C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;UClhB7C,qCAAqC;;;;;UCArC;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA,EAAE;UACF;UACA","sources":["webpack://gutenbuild/./src/components/tabs/data/context.js","webpack://gutenbuild/./node_modules/graphemesplit/index.js","webpack://gutenbuild/./node_modules/graphemesplit/types.js","webpack://gutenbuild/./node_modules/js-base64/base64.js","webpack://gutenbuild/./node_modules/tiny-inflate/index.js","webpack://gutenbuild/./node_modules/unicode-trie/index.js","webpack://gutenbuild/./node_modules/unicode-trie/swap.js","webpack://gutenbuild/./node_modules/fast-fuzzy/lib/fuzzy.mjs","webpack://gutenbuild/webpack/runtime/getFullHash","webpack://gutenbuild/webpack/runtime/harmony module decorator"],"sourcesContent":["/**\n * External dependencies\n */\n\nimport { search as fastSearch } from 'fast-fuzzy';\n\n/**\n * WordPress dependencies\n */\nimport { useState, createContext, useContext } from '@wordpress/element';\n\n/**\n * Module Constants\n */\nconst MAX_RESULTS = 24;\n\nconst StateContext = createContext();\n\nconst getType = ( obj, lib, prop ) => {\n\tif ( lib === 'components' || obj[ lib ][ prop ].$$typeof || prop[0] === prop[0].toUpperCase() ) {\n\t\treturn 'component';\n\t}\n\n\treturn typeof obj[ lib ][ prop ];\n};\n\n\nconst getDocLink = ( lib ) => {\n    console.log(lib);\n    // switch (lib) {\n    //     case 'block'\n    // }\n\n\treturn `https://developer.wordpress.org/block-editor/reference-guides/data/data-core${ module }`;\n};\n\nconst getDocModule = ( activeStore ) => {\n\tconst s = activeStore.split( '/' );\n\n\t// Not Core\n\tif ( s[ 1 ] ) {\n\t\treturn '-' + s[ 1 ];\n\t}\n\n\treturn '';\n};\n\n\nconst flatten = ( obj ) => {\n\tvar out = [];\n\n\tfor ( var lib in obj ) {\n\t\tfor ( var prop in obj[ lib ] ) {\n\t\t\tif ( obj[ lib ][ prop ] ) {\n\t\t\t\tout.push( {\n\t\t\t\t\ttext: `${ lib }.${ prop }`,\n\t\t\t\t\ttype: getType( obj, lib, prop ),\n                    docLink : getDocLink(lib)\n\t\t\t\t} );\n\t\t\t}\n\t\t}\n\t}\n\treturn out;\n};\n\n\nexport function DataTabProvider( { children } ) {\n\tconst [ action, setAction ] = useState( 'select' );\n\tconst [ activeStore, setActiveStore ] = useState( null );\n\tconst [ activeFunction, setActiveFunction ] = useState( null );\n\tlet allData = flatten( wp );\n\n\tconst stores = {};\n\n\tfor ( let i = 0; i < Object.keys( wp ).length; i++ ) {\n\t\tconst key = Object.keys( wp )[ i ];\n\t\tif ( wp[ key ].store ) {\n\t\t\tstores[ key ] = wp[ key ];\n\t\t}\n\t}\n\tconst storeNames = Object.keys( stores ).map(\n\t\t( i ) => stores[ i ].store.name\n\t);\n\n\t// Add Select Functions\n\tfor ( let k = 0; k < storeNames.length; k++ ) {\n\t\tconst store = storeNames[ k ];\n\t\tallData = allData.concat(\n\t\t\tflatten( {\n\t\t\t\t[ `data.select('${ store }')` ]: wp.data.select( store ),\n\t\t\t} )\n\t\t);\n\t}\n\n\t// Add Dispatch Functions\n\tfor ( let k = 0; k < storeNames.length; k++ ) {\n\t\tconst store = storeNames[ k ];\n\t\tallData = allData.concat(\n\t\t\tflatten( {\n\t\t\t\t[ `data.dispatch('${ store }')` ]: wp.data.dispatch( store ),\n\t\t\t} )\n\t\t);\n\t}\n\n\tconst search = ( keyword ) => {\n\t\tconst results = fastSearch( keyword, allData, {\n\t\t\tignoreCase: true,\n\t\t\tkeySelector: ( obj ) => obj.text,\n\t\t} );\n\t\treturn results.splice( 0, MAX_RESULTS );\n\t};\n\n\treturn (\n\t\t<StateContext.Provider\n\t\t\tvalue={ {\n\t\t\t\taction,\n\t\t\t\tsetAction,\n\t\t\t\tactiveStore,\n\t\t\t\tsetActiveStore,\n\t\t\t\tactiveFunction,\n\t\t\t\tsetActiveFunction,\n\t\t\t\tstores,\n\t\t\t\tsearch,\n\t\t\t} }\n\t\t>\n\t\t\t{ children }\n\t\t</StateContext.Provider>\n\t);\n}\n\nexport function useDataTab() {\n\tconst context = useContext( StateContext );\n\n\tif ( context === undefined ) {\n\t\tthrow new Error( 'useData must be used within a Provider' );\n\t}\n\n\treturn context;\n}\n","const types = require(\"./types\");\nconst typeTrieData = require(\"./typeTrie.json\").data;\nconst extPictData = require(\"./extPict.json\").data;\n\nconst UnicodeTrie = require(\"unicode-trie\");\nconst Base64 = require(\"js-base64\").Base64;\n\nconst typeTrie = new UnicodeTrie(Base64.toUint8Array(typeTrieData));\nconst extPict = new UnicodeTrie(Base64.toUint8Array(extPictData));\n\nfunction is(type, bit) {\n  return (type & bit) !== 0;\n}\n\nconst GB11State = {\n  Initial: 0,\n  ExtendOrZWJ: 1,\n  NotBoundary: 2,\n};\n\nfunction nextGraphemeClusterSize(ts, start) {\n  const L = ts.length;\n\n  let ri = 0;\n  let gb11State = GB11State.Initial;\n\n  // GB1: sot ÷ Any\n  for (let i = start; i + 1 < L; i++) {\n    const curr = ts[i + 0];\n    const next = ts[i + 1];\n\n    // for GB12, GB13\n    if (!is(curr, types.Regional_Indicator)) {\n      ri = 0;\n    }\n\n    // for GB11: \\p{Extended_Pictographic} Extend* ZWJ x \\p{Extended_Pictographic}\n    switch (gb11State) {\n      case GB11State.NotBoundary:\n      case GB11State.Initial:\n        if (is(curr, types.Extended_Pictographic)) {\n          gb11State = GB11State.ExtendOrZWJ;\n        } else {\n          gb11State = GB11State.Initial;\n        }\n        break;\n      case GB11State.ExtendOrZWJ:\n        if (is(curr, types.Extend)) {\n          gb11State = GB11State.ExtendOrZWJ;\n        } else if (\n          is(curr, types.ZWJ) &&\n          is(next, types.Extended_Pictographic)\n        ) {\n          gb11State = GB11State.NotBoundary;\n        } else {\n          gb11State = GB11State.Initial;\n        }\n        break;\n    }\n\n    // GB3: CR x LF\n    if (is(curr, types.CR) && is(next, types.LF)) {\n      continue;\n    }\n    // GB4: (Control | CR | LF) ÷\n    if (is(curr, types.Control | types.CR | types.LF)) {\n      return i + 1 - start;\n    }\n    // GB5: ÷ (Control | CR | LF)\n    if (is(next, types.Control | types.CR | types.LF)) {\n      return i + 1 - start;\n    }\n    // GB6: L x (L | V | LV | LVT)\n    if (\n      is(curr, types.L) &&\n      is(next, types.L | types.V | types.LV | types.LVT)\n    ) {\n      continue;\n    }\n    // GB7: (LV | V) x (V | T)\n    if (is(curr, types.LV | types.V) && is(next, types.V | types.T)) {\n      continue;\n    }\n    // GB8: (LVT | T) x T\n    if (is(curr, types.LVT | types.T) && is(next, types.T)) {\n      continue;\n    }\n    // GB9: x (Extend | ZWJ)\n    if (is(next, types.Extend | types.ZWJ)) {\n      continue;\n    }\n    // GB9a: x SpacingMark\n    if (is(next, types.SpacingMark)) {\n      continue;\n    }\n    // GB9b: Prepend x\n    if (is(curr, types.Prepend)) {\n      continue;\n    }\n    // GB11: \\p{Extended_Pictographic} Extend* ZWJ x \\p{Extended_Pictographic}\n    if (gb11State === GB11State.NotBoundary) {\n      continue;\n    }\n    // GB12: sot (RI RI)* RI x RI\n    // GB13: [^RI] (RI RI)* RI x RI\n    if (\n      is(curr, types.Regional_Indicator) &&\n      is(next, types.Regional_Indicator) &&\n      ri % 2 === 0\n    ) {\n      ri++;\n      continue;\n    }\n    // GB999: Any ÷ Any\n    return i + 1 - start;\n  }\n  // GB2: Any ÷ eot\n  return L - start;\n}\n\nmodule.exports = function split(str) {\n  const graphemeClusters = [];\n\n  const map = [0];\n  const ts = [];\n  for (let i = 0; i < str.length; ) {\n    const code = str.codePointAt(i);\n    ts.push(typeTrie.get(code) | extPict.get(code));\n    i += code > 65535 ? 2 : 1;\n    map.push(i);\n  }\n\n  for (let offset = 0; offset < ts.length; ) {\n    const size = nextGraphemeClusterSize(ts, offset);\n    const start = map[offset];\n    const end = map[offset + size];\n    graphemeClusters.push(str.slice(start, end));\n    offset += size;\n  }\n\n  return graphemeClusters;\n};\n","module.exports = {\n  Other: 0,\n  CR: 1 << 0,\n  LF: 1 << 1,\n  Control: 1 << 2,\n  Extend: 1 << 3,\n  ZWJ: 1 << 4,\n  Regional_Indicator: 1 << 5,\n  Prepend: 1 << 6,\n  SpacingMark: 1 << 7,\n  L: 1 << 8,\n  V: 1 << 9,\n  T: 1 << 10,\n  LV: 1 << 11,\n  LVT: 1 << 12,\n  Extended_Pictographic: 1 << 13,\n};\n","//\n// THIS FILE IS AUTOMATICALLY GENERATED! DO NOT EDIT BY HAND!\n//\n;\n(function (global, factory) {\n    typeof exports === 'object' && typeof module !== 'undefined'\n        ? module.exports = factory()\n        : typeof define === 'function' && define.amd\n            ? define(factory) :\n            // cf. https://github.com/dankogai/js-base64/issues/119\n            (function () {\n                // existing version for noConflict()\n                var _Base64 = global.Base64;\n                var gBase64 = factory();\n                gBase64.noConflict = function () {\n                    global.Base64 = _Base64;\n                    return gBase64;\n                };\n                if (global.Meteor) { // Meteor.js\n                    Base64 = gBase64;\n                }\n                global.Base64 = gBase64;\n            })();\n}((typeof self !== 'undefined' ? self\n    : typeof window !== 'undefined' ? window\n        : typeof global !== 'undefined' ? global\n            : this), function () {\n    'use strict';\n    /**\n     *  base64.ts\n     *\n     *  Licensed under the BSD 3-Clause License.\n     *    http://opensource.org/licenses/BSD-3-Clause\n     *\n     *  References:\n     *    http://en.wikipedia.org/wiki/Base64\n     *\n     * @author Dan Kogai (https://github.com/dankogai)\n     */\n    var version = '3.7.2';\n    /**\n     * @deprecated use lowercase `version`.\n     */\n    var VERSION = version;\n    var _hasatob = typeof atob === 'function';\n    var _hasbtoa = typeof btoa === 'function';\n    var _hasBuffer = typeof Buffer === 'function';\n    var _TD = typeof TextDecoder === 'function' ? new TextDecoder() : undefined;\n    var _TE = typeof TextEncoder === 'function' ? new TextEncoder() : undefined;\n    var b64ch = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=';\n    var b64chs = Array.prototype.slice.call(b64ch);\n    var b64tab = (function (a) {\n        var tab = {};\n        a.forEach(function (c, i) { return tab[c] = i; });\n        return tab;\n    })(b64chs);\n    var b64re = /^(?:[A-Za-z\\d+\\/]{4})*?(?:[A-Za-z\\d+\\/]{2}(?:==)?|[A-Za-z\\d+\\/]{3}=?)?$/;\n    var _fromCC = String.fromCharCode.bind(String);\n    var _U8Afrom = typeof Uint8Array.from === 'function'\n        ? Uint8Array.from.bind(Uint8Array)\n        : function (it, fn) {\n            if (fn === void 0) { fn = function (x) { return x; }; }\n            return new Uint8Array(Array.prototype.slice.call(it, 0).map(fn));\n        };\n    var _mkUriSafe = function (src) { return src\n        .replace(/=/g, '').replace(/[+\\/]/g, function (m0) { return m0 == '+' ? '-' : '_'; }); };\n    var _tidyB64 = function (s) { return s.replace(/[^A-Za-z0-9\\+\\/]/g, ''); };\n    /**\n     * polyfill version of `btoa`\n     */\n    var btoaPolyfill = function (bin) {\n        // console.log('polyfilled');\n        var u32, c0, c1, c2, asc = '';\n        var pad = bin.length % 3;\n        for (var i = 0; i < bin.length;) {\n            if ((c0 = bin.charCodeAt(i++)) > 255 ||\n                (c1 = bin.charCodeAt(i++)) > 255 ||\n                (c2 = bin.charCodeAt(i++)) > 255)\n                throw new TypeError('invalid character found');\n            u32 = (c0 << 16) | (c1 << 8) | c2;\n            asc += b64chs[u32 >> 18 & 63]\n                + b64chs[u32 >> 12 & 63]\n                + b64chs[u32 >> 6 & 63]\n                + b64chs[u32 & 63];\n        }\n        return pad ? asc.slice(0, pad - 3) + \"===\".substring(pad) : asc;\n    };\n    /**\n     * does what `window.btoa` of web browsers do.\n     * @param {String} bin binary string\n     * @returns {string} Base64-encoded string\n     */\n    var _btoa = _hasbtoa ? function (bin) { return btoa(bin); }\n        : _hasBuffer ? function (bin) { return Buffer.from(bin, 'binary').toString('base64'); }\n            : btoaPolyfill;\n    var _fromUint8Array = _hasBuffer\n        ? function (u8a) { return Buffer.from(u8a).toString('base64'); }\n        : function (u8a) {\n            // cf. https://stackoverflow.com/questions/12710001/how-to-convert-uint8-array-to-base64-encoded-string/12713326#12713326\n            var maxargs = 0x1000;\n            var strs = [];\n            for (var i = 0, l = u8a.length; i < l; i += maxargs) {\n                strs.push(_fromCC.apply(null, u8a.subarray(i, i + maxargs)));\n            }\n            return _btoa(strs.join(''));\n        };\n    /**\n     * converts a Uint8Array to a Base64 string.\n     * @param {boolean} [urlsafe] URL-and-filename-safe a la RFC4648 §5\n     * @returns {string} Base64 string\n     */\n    var fromUint8Array = function (u8a, urlsafe) {\n        if (urlsafe === void 0) { urlsafe = false; }\n        return urlsafe ? _mkUriSafe(_fromUint8Array(u8a)) : _fromUint8Array(u8a);\n    };\n    // This trick is found broken https://github.com/dankogai/js-base64/issues/130\n    // const utob = (src: string) => unescape(encodeURIComponent(src));\n    // reverting good old fationed regexp\n    var cb_utob = function (c) {\n        if (c.length < 2) {\n            var cc = c.charCodeAt(0);\n            return cc < 0x80 ? c\n                : cc < 0x800 ? (_fromCC(0xc0 | (cc >>> 6))\n                    + _fromCC(0x80 | (cc & 0x3f)))\n                    : (_fromCC(0xe0 | ((cc >>> 12) & 0x0f))\n                        + _fromCC(0x80 | ((cc >>> 6) & 0x3f))\n                        + _fromCC(0x80 | (cc & 0x3f)));\n        }\n        else {\n            var cc = 0x10000\n                + (c.charCodeAt(0) - 0xD800) * 0x400\n                + (c.charCodeAt(1) - 0xDC00);\n            return (_fromCC(0xf0 | ((cc >>> 18) & 0x07))\n                + _fromCC(0x80 | ((cc >>> 12) & 0x3f))\n                + _fromCC(0x80 | ((cc >>> 6) & 0x3f))\n                + _fromCC(0x80 | (cc & 0x3f)));\n        }\n    };\n    var re_utob = /[\\uD800-\\uDBFF][\\uDC00-\\uDFFFF]|[^\\x00-\\x7F]/g;\n    /**\n     * @deprecated should have been internal use only.\n     * @param {string} src UTF-8 string\n     * @returns {string} UTF-16 string\n     */\n    var utob = function (u) { return u.replace(re_utob, cb_utob); };\n    //\n    var _encode = _hasBuffer\n        ? function (s) { return Buffer.from(s, 'utf8').toString('base64'); }\n        : _TE\n            ? function (s) { return _fromUint8Array(_TE.encode(s)); }\n            : function (s) { return _btoa(utob(s)); };\n    /**\n     * converts a UTF-8-encoded string to a Base64 string.\n     * @param {boolean} [urlsafe] if `true` make the result URL-safe\n     * @returns {string} Base64 string\n     */\n    var encode = function (src, urlsafe) {\n        if (urlsafe === void 0) { urlsafe = false; }\n        return urlsafe\n            ? _mkUriSafe(_encode(src))\n            : _encode(src);\n    };\n    /**\n     * converts a UTF-8-encoded string to URL-safe Base64 RFC4648 §5.\n     * @returns {string} Base64 string\n     */\n    var encodeURI = function (src) { return encode(src, true); };\n    // This trick is found broken https://github.com/dankogai/js-base64/issues/130\n    // const btou = (src: string) => decodeURIComponent(escape(src));\n    // reverting good old fationed regexp\n    var re_btou = /[\\xC0-\\xDF][\\x80-\\xBF]|[\\xE0-\\xEF][\\x80-\\xBF]{2}|[\\xF0-\\xF7][\\x80-\\xBF]{3}/g;\n    var cb_btou = function (cccc) {\n        switch (cccc.length) {\n            case 4:\n                var cp = ((0x07 & cccc.charCodeAt(0)) << 18)\n                    | ((0x3f & cccc.charCodeAt(1)) << 12)\n                    | ((0x3f & cccc.charCodeAt(2)) << 6)\n                    | (0x3f & cccc.charCodeAt(3)), offset = cp - 0x10000;\n                return (_fromCC((offset >>> 10) + 0xD800)\n                    + _fromCC((offset & 0x3FF) + 0xDC00));\n            case 3:\n                return _fromCC(((0x0f & cccc.charCodeAt(0)) << 12)\n                    | ((0x3f & cccc.charCodeAt(1)) << 6)\n                    | (0x3f & cccc.charCodeAt(2)));\n            default:\n                return _fromCC(((0x1f & cccc.charCodeAt(0)) << 6)\n                    | (0x3f & cccc.charCodeAt(1)));\n        }\n    };\n    /**\n     * @deprecated should have been internal use only.\n     * @param {string} src UTF-16 string\n     * @returns {string} UTF-8 string\n     */\n    var btou = function (b) { return b.replace(re_btou, cb_btou); };\n    /**\n     * polyfill version of `atob`\n     */\n    var atobPolyfill = function (asc) {\n        // console.log('polyfilled');\n        asc = asc.replace(/\\s+/g, '');\n        if (!b64re.test(asc))\n            throw new TypeError('malformed base64.');\n        asc += '=='.slice(2 - (asc.length & 3));\n        var u24, bin = '', r1, r2;\n        for (var i = 0; i < asc.length;) {\n            u24 = b64tab[asc.charAt(i++)] << 18\n                | b64tab[asc.charAt(i++)] << 12\n                | (r1 = b64tab[asc.charAt(i++)]) << 6\n                | (r2 = b64tab[asc.charAt(i++)]);\n            bin += r1 === 64 ? _fromCC(u24 >> 16 & 255)\n                : r2 === 64 ? _fromCC(u24 >> 16 & 255, u24 >> 8 & 255)\n                    : _fromCC(u24 >> 16 & 255, u24 >> 8 & 255, u24 & 255);\n        }\n        return bin;\n    };\n    /**\n     * does what `window.atob` of web browsers do.\n     * @param {String} asc Base64-encoded string\n     * @returns {string} binary string\n     */\n    var _atob = _hasatob ? function (asc) { return atob(_tidyB64(asc)); }\n        : _hasBuffer ? function (asc) { return Buffer.from(asc, 'base64').toString('binary'); }\n            : atobPolyfill;\n    //\n    var _toUint8Array = _hasBuffer\n        ? function (a) { return _U8Afrom(Buffer.from(a, 'base64')); }\n        : function (a) { return _U8Afrom(_atob(a), function (c) { return c.charCodeAt(0); }); };\n    /**\n     * converts a Base64 string to a Uint8Array.\n     */\n    var toUint8Array = function (a) { return _toUint8Array(_unURI(a)); };\n    //\n    var _decode = _hasBuffer\n        ? function (a) { return Buffer.from(a, 'base64').toString('utf8'); }\n        : _TD\n            ? function (a) { return _TD.decode(_toUint8Array(a)); }\n            : function (a) { return btou(_atob(a)); };\n    var _unURI = function (a) { return _tidyB64(a.replace(/[-_]/g, function (m0) { return m0 == '-' ? '+' : '/'; })); };\n    /**\n     * converts a Base64 string to a UTF-8 string.\n     * @param {String} src Base64 string.  Both normal and URL-safe are supported\n     * @returns {string} UTF-8 string\n     */\n    var decode = function (src) { return _decode(_unURI(src)); };\n    /**\n     * check if a value is a valid Base64 string\n     * @param {String} src a value to check\n      */\n    var isValid = function (src) {\n        if (typeof src !== 'string')\n            return false;\n        var s = src.replace(/\\s+/g, '').replace(/={0,2}$/, '');\n        return !/[^\\s0-9a-zA-Z\\+/]/.test(s) || !/[^\\s0-9a-zA-Z\\-_]/.test(s);\n    };\n    //\n    var _noEnum = function (v) {\n        return {\n            value: v, enumerable: false, writable: true, configurable: true\n        };\n    };\n    /**\n     * extend String.prototype with relevant methods\n     */\n    var extendString = function () {\n        var _add = function (name, body) { return Object.defineProperty(String.prototype, name, _noEnum(body)); };\n        _add('fromBase64', function () { return decode(this); });\n        _add('toBase64', function (urlsafe) { return encode(this, urlsafe); });\n        _add('toBase64URI', function () { return encode(this, true); });\n        _add('toBase64URL', function () { return encode(this, true); });\n        _add('toUint8Array', function () { return toUint8Array(this); });\n    };\n    /**\n     * extend Uint8Array.prototype with relevant methods\n     */\n    var extendUint8Array = function () {\n        var _add = function (name, body) { return Object.defineProperty(Uint8Array.prototype, name, _noEnum(body)); };\n        _add('toBase64', function (urlsafe) { return fromUint8Array(this, urlsafe); });\n        _add('toBase64URI', function () { return fromUint8Array(this, true); });\n        _add('toBase64URL', function () { return fromUint8Array(this, true); });\n    };\n    /**\n     * extend Builtin prototypes with relevant methods\n     */\n    var extendBuiltins = function () {\n        extendString();\n        extendUint8Array();\n    };\n    var gBase64 = {\n        version: version,\n        VERSION: VERSION,\n        atob: _atob,\n        atobPolyfill: atobPolyfill,\n        btoa: _btoa,\n        btoaPolyfill: btoaPolyfill,\n        fromBase64: decode,\n        toBase64: encode,\n        encode: encode,\n        encodeURI: encodeURI,\n        encodeURL: encodeURI,\n        utob: utob,\n        btou: btou,\n        decode: decode,\n        isValid: isValid,\n        fromUint8Array: fromUint8Array,\n        toUint8Array: toUint8Array,\n        extendString: extendString,\n        extendUint8Array: extendUint8Array,\n        extendBuiltins: extendBuiltins\n    };\n    //\n    // export Base64 to the namespace\n    //\n    // ES5 is yet to have Object.assign() that may make transpilers unhappy.\n    // gBase64.Base64 = Object.assign({}, gBase64);\n    gBase64.Base64 = {};\n    Object.keys(gBase64).forEach(function (k) { return gBase64.Base64[k] = gBase64[k]; });\n    return gBase64;\n}));\n","var TINF_OK = 0;\nvar TINF_DATA_ERROR = -3;\n\nfunction Tree() {\n  this.table = new Uint16Array(16);   /* table of code length counts */\n  this.trans = new Uint16Array(288);  /* code -> symbol translation table */\n}\n\nfunction Data(source, dest) {\n  this.source = source;\n  this.sourceIndex = 0;\n  this.tag = 0;\n  this.bitcount = 0;\n  \n  this.dest = dest;\n  this.destLen = 0;\n  \n  this.ltree = new Tree();  /* dynamic length/symbol tree */\n  this.dtree = new Tree();  /* dynamic distance tree */\n}\n\n/* --------------------------------------------------- *\n * -- uninitialized global data (static structures) -- *\n * --------------------------------------------------- */\n\nvar sltree = new Tree();\nvar sdtree = new Tree();\n\n/* extra bits and base tables for length codes */\nvar length_bits = new Uint8Array(30);\nvar length_base = new Uint16Array(30);\n\n/* extra bits and base tables for distance codes */\nvar dist_bits = new Uint8Array(30);\nvar dist_base = new Uint16Array(30);\n\n/* special ordering of code length codes */\nvar clcidx = new Uint8Array([\n  16, 17, 18, 0, 8, 7, 9, 6,\n  10, 5, 11, 4, 12, 3, 13, 2,\n  14, 1, 15\n]);\n\n/* used by tinf_decode_trees, avoids allocations every call */\nvar code_tree = new Tree();\nvar lengths = new Uint8Array(288 + 32);\n\n/* ----------------------- *\n * -- utility functions -- *\n * ----------------------- */\n\n/* build extra bits and base tables */\nfunction tinf_build_bits_base(bits, base, delta, first) {\n  var i, sum;\n\n  /* build bits table */\n  for (i = 0; i < delta; ++i) bits[i] = 0;\n  for (i = 0; i < 30 - delta; ++i) bits[i + delta] = i / delta | 0;\n\n  /* build base table */\n  for (sum = first, i = 0; i < 30; ++i) {\n    base[i] = sum;\n    sum += 1 << bits[i];\n  }\n}\n\n/* build the fixed huffman trees */\nfunction tinf_build_fixed_trees(lt, dt) {\n  var i;\n\n  /* build fixed length tree */\n  for (i = 0; i < 7; ++i) lt.table[i] = 0;\n\n  lt.table[7] = 24;\n  lt.table[8] = 152;\n  lt.table[9] = 112;\n\n  for (i = 0; i < 24; ++i) lt.trans[i] = 256 + i;\n  for (i = 0; i < 144; ++i) lt.trans[24 + i] = i;\n  for (i = 0; i < 8; ++i) lt.trans[24 + 144 + i] = 280 + i;\n  for (i = 0; i < 112; ++i) lt.trans[24 + 144 + 8 + i] = 144 + i;\n\n  /* build fixed distance tree */\n  for (i = 0; i < 5; ++i) dt.table[i] = 0;\n\n  dt.table[5] = 32;\n\n  for (i = 0; i < 32; ++i) dt.trans[i] = i;\n}\n\n/* given an array of code lengths, build a tree */\nvar offs = new Uint16Array(16);\n\nfunction tinf_build_tree(t, lengths, off, num) {\n  var i, sum;\n\n  /* clear code length count table */\n  for (i = 0; i < 16; ++i) t.table[i] = 0;\n\n  /* scan symbol lengths, and sum code length counts */\n  for (i = 0; i < num; ++i) t.table[lengths[off + i]]++;\n\n  t.table[0] = 0;\n\n  /* compute offset table for distribution sort */\n  for (sum = 0, i = 0; i < 16; ++i) {\n    offs[i] = sum;\n    sum += t.table[i];\n  }\n\n  /* create code->symbol translation table (symbols sorted by code) */\n  for (i = 0; i < num; ++i) {\n    if (lengths[off + i]) t.trans[offs[lengths[off + i]]++] = i;\n  }\n}\n\n/* ---------------------- *\n * -- decode functions -- *\n * ---------------------- */\n\n/* get one bit from source stream */\nfunction tinf_getbit(d) {\n  /* check if tag is empty */\n  if (!d.bitcount--) {\n    /* load next tag */\n    d.tag = d.source[d.sourceIndex++];\n    d.bitcount = 7;\n  }\n\n  /* shift bit out of tag */\n  var bit = d.tag & 1;\n  d.tag >>>= 1;\n\n  return bit;\n}\n\n/* read a num bit value from a stream and add base */\nfunction tinf_read_bits(d, num, base) {\n  if (!num)\n    return base;\n\n  while (d.bitcount < 24) {\n    d.tag |= d.source[d.sourceIndex++] << d.bitcount;\n    d.bitcount += 8;\n  }\n\n  var val = d.tag & (0xffff >>> (16 - num));\n  d.tag >>>= num;\n  d.bitcount -= num;\n  return val + base;\n}\n\n/* given a data stream and a tree, decode a symbol */\nfunction tinf_decode_symbol(d, t) {\n  while (d.bitcount < 24) {\n    d.tag |= d.source[d.sourceIndex++] << d.bitcount;\n    d.bitcount += 8;\n  }\n  \n  var sum = 0, cur = 0, len = 0;\n  var tag = d.tag;\n\n  /* get more bits while code value is above sum */\n  do {\n    cur = 2 * cur + (tag & 1);\n    tag >>>= 1;\n    ++len;\n\n    sum += t.table[len];\n    cur -= t.table[len];\n  } while (cur >= 0);\n  \n  d.tag = tag;\n  d.bitcount -= len;\n\n  return t.trans[sum + cur];\n}\n\n/* given a data stream, decode dynamic trees from it */\nfunction tinf_decode_trees(d, lt, dt) {\n  var hlit, hdist, hclen;\n  var i, num, length;\n\n  /* get 5 bits HLIT (257-286) */\n  hlit = tinf_read_bits(d, 5, 257);\n\n  /* get 5 bits HDIST (1-32) */\n  hdist = tinf_read_bits(d, 5, 1);\n\n  /* get 4 bits HCLEN (4-19) */\n  hclen = tinf_read_bits(d, 4, 4);\n\n  for (i = 0; i < 19; ++i) lengths[i] = 0;\n\n  /* read code lengths for code length alphabet */\n  for (i = 0; i < hclen; ++i) {\n    /* get 3 bits code length (0-7) */\n    var clen = tinf_read_bits(d, 3, 0);\n    lengths[clcidx[i]] = clen;\n  }\n\n  /* build code length tree */\n  tinf_build_tree(code_tree, lengths, 0, 19);\n\n  /* decode code lengths for the dynamic trees */\n  for (num = 0; num < hlit + hdist;) {\n    var sym = tinf_decode_symbol(d, code_tree);\n\n    switch (sym) {\n      case 16:\n        /* copy previous code length 3-6 times (read 2 bits) */\n        var prev = lengths[num - 1];\n        for (length = tinf_read_bits(d, 2, 3); length; --length) {\n          lengths[num++] = prev;\n        }\n        break;\n      case 17:\n        /* repeat code length 0 for 3-10 times (read 3 bits) */\n        for (length = tinf_read_bits(d, 3, 3); length; --length) {\n          lengths[num++] = 0;\n        }\n        break;\n      case 18:\n        /* repeat code length 0 for 11-138 times (read 7 bits) */\n        for (length = tinf_read_bits(d, 7, 11); length; --length) {\n          lengths[num++] = 0;\n        }\n        break;\n      default:\n        /* values 0-15 represent the actual code lengths */\n        lengths[num++] = sym;\n        break;\n    }\n  }\n\n  /* build dynamic trees */\n  tinf_build_tree(lt, lengths, 0, hlit);\n  tinf_build_tree(dt, lengths, hlit, hdist);\n}\n\n/* ----------------------------- *\n * -- block inflate functions -- *\n * ----------------------------- */\n\n/* given a stream and two trees, inflate a block of data */\nfunction tinf_inflate_block_data(d, lt, dt) {\n  while (1) {\n    var sym = tinf_decode_symbol(d, lt);\n\n    /* check for end of block */\n    if (sym === 256) {\n      return TINF_OK;\n    }\n\n    if (sym < 256) {\n      d.dest[d.destLen++] = sym;\n    } else {\n      var length, dist, offs;\n      var i;\n\n      sym -= 257;\n\n      /* possibly get more bits from length code */\n      length = tinf_read_bits(d, length_bits[sym], length_base[sym]);\n\n      dist = tinf_decode_symbol(d, dt);\n\n      /* possibly get more bits from distance code */\n      offs = d.destLen - tinf_read_bits(d, dist_bits[dist], dist_base[dist]);\n\n      /* copy match */\n      for (i = offs; i < offs + length; ++i) {\n        d.dest[d.destLen++] = d.dest[i];\n      }\n    }\n  }\n}\n\n/* inflate an uncompressed block of data */\nfunction tinf_inflate_uncompressed_block(d) {\n  var length, invlength;\n  var i;\n  \n  /* unread from bitbuffer */\n  while (d.bitcount > 8) {\n    d.sourceIndex--;\n    d.bitcount -= 8;\n  }\n\n  /* get length */\n  length = d.source[d.sourceIndex + 1];\n  length = 256 * length + d.source[d.sourceIndex];\n\n  /* get one's complement of length */\n  invlength = d.source[d.sourceIndex + 3];\n  invlength = 256 * invlength + d.source[d.sourceIndex + 2];\n\n  /* check length */\n  if (length !== (~invlength & 0x0000ffff))\n    return TINF_DATA_ERROR;\n\n  d.sourceIndex += 4;\n\n  /* copy block */\n  for (i = length; i; --i)\n    d.dest[d.destLen++] = d.source[d.sourceIndex++];\n\n  /* make sure we start next block on a byte boundary */\n  d.bitcount = 0;\n\n  return TINF_OK;\n}\n\n/* inflate stream from source to dest */\nfunction tinf_uncompress(source, dest) {\n  var d = new Data(source, dest);\n  var bfinal, btype, res;\n\n  do {\n    /* read final block flag */\n    bfinal = tinf_getbit(d);\n\n    /* read block type (2 bits) */\n    btype = tinf_read_bits(d, 2, 0);\n\n    /* decompress block */\n    switch (btype) {\n      case 0:\n        /* decompress uncompressed block */\n        res = tinf_inflate_uncompressed_block(d);\n        break;\n      case 1:\n        /* decompress block with fixed huffman trees */\n        res = tinf_inflate_block_data(d, sltree, sdtree);\n        break;\n      case 2:\n        /* decompress block with dynamic huffman trees */\n        tinf_decode_trees(d, d.ltree, d.dtree);\n        res = tinf_inflate_block_data(d, d.ltree, d.dtree);\n        break;\n      default:\n        res = TINF_DATA_ERROR;\n    }\n\n    if (res !== TINF_OK)\n      throw new Error('Data error');\n\n  } while (!bfinal);\n\n  if (d.destLen < d.dest.length) {\n    if (typeof d.dest.slice === 'function')\n      return d.dest.slice(0, d.destLen);\n    else\n      return d.dest.subarray(0, d.destLen);\n  }\n  \n  return d.dest;\n}\n\n/* -------------------- *\n * -- initialization -- *\n * -------------------- */\n\n/* build fixed huffman trees */\ntinf_build_fixed_trees(sltree, sdtree);\n\n/* build extra bits and base tables */\ntinf_build_bits_base(length_bits, length_base, 4, 3);\ntinf_build_bits_base(dist_bits, dist_base, 2, 1);\n\n/* fix a special case */\nlength_bits[28] = 0;\nlength_base[28] = 258;\n\nmodule.exports = tinf_uncompress;\n","const inflate = require('tiny-inflate');\nconst { swap32LE } = require('./swap');\n\n// Shift size for getting the index-1 table offset.\nconst SHIFT_1 = 6 + 5;\n\n// Shift size for getting the index-2 table offset.\nconst SHIFT_2 = 5;\n\n// Difference between the two shift sizes,\n// for getting an index-1 offset from an index-2 offset. 6=11-5\nconst SHIFT_1_2 = SHIFT_1 - SHIFT_2;\n\n// Number of index-1 entries for the BMP. 32=0x20\n// This part of the index-1 table is omitted from the serialized form.\nconst OMITTED_BMP_INDEX_1_LENGTH = 0x10000 >> SHIFT_1;\n\n// Number of entries in an index-2 block. 64=0x40\nconst INDEX_2_BLOCK_LENGTH = 1 << SHIFT_1_2;\n\n// Mask for getting the lower bits for the in-index-2-block offset. */\nconst INDEX_2_MASK = INDEX_2_BLOCK_LENGTH - 1;\n\n// Shift size for shifting left the index array values.\n// Increases possible data size with 16-bit index values at the cost\n// of compactability.\n// This requires data blocks to be aligned by DATA_GRANULARITY.\nconst INDEX_SHIFT = 2;\n\n// Number of entries in a data block. 32=0x20\nconst DATA_BLOCK_LENGTH = 1 << SHIFT_2;\n\n// Mask for getting the lower bits for the in-data-block offset.\nconst DATA_MASK = DATA_BLOCK_LENGTH - 1;\n\n// The part of the index-2 table for U+D800..U+DBFF stores values for\n// lead surrogate code _units_ not code _points_.\n// Values for lead surrogate code _points_ are indexed with this portion of the table.\n// Length=32=0x20=0x400>>SHIFT_2. (There are 1024=0x400 lead surrogates.)\nconst LSCP_INDEX_2_OFFSET = 0x10000 >> SHIFT_2;\nconst LSCP_INDEX_2_LENGTH = 0x400 >> SHIFT_2;\n\n// Count the lengths of both BMP pieces. 2080=0x820\nconst INDEX_2_BMP_LENGTH = LSCP_INDEX_2_OFFSET + LSCP_INDEX_2_LENGTH;\n\n// The 2-byte UTF-8 version of the index-2 table follows at offset 2080=0x820.\n// Length 32=0x20 for lead bytes C0..DF, regardless of SHIFT_2.\nconst UTF8_2B_INDEX_2_OFFSET = INDEX_2_BMP_LENGTH;\nconst UTF8_2B_INDEX_2_LENGTH = 0x800 >> 6;  // U+0800 is the first code point after 2-byte UTF-8\n\n// The index-1 table, only used for supplementary code points, at offset 2112=0x840.\n// Variable length, for code points up to highStart, where the last single-value range starts.\n// Maximum length 512=0x200=0x100000>>SHIFT_1.\n// (For 0x100000 supplementary code points U+10000..U+10ffff.)\n//\n// The part of the index-2 table for supplementary code points starts\n// after this index-1 table.\n//\n// Both the index-1 table and the following part of the index-2 table\n// are omitted completely if there is only BMP data.\nconst INDEX_1_OFFSET = UTF8_2B_INDEX_2_OFFSET + UTF8_2B_INDEX_2_LENGTH;\n\n// The alignment size of a data block. Also the granularity for compaction.\nconst DATA_GRANULARITY = 1 << INDEX_SHIFT;\n\nclass UnicodeTrie {\n  constructor(data) {\n    const isBuffer = (typeof data.readUInt32BE === 'function') && (typeof data.slice === 'function');\n\n    if (isBuffer || data instanceof Uint8Array) {\n      // read binary format\n      let uncompressedLength;\n      if (isBuffer) {\n        this.highStart = data.readUInt32LE(0);\n        this.errorValue = data.readUInt32LE(4);\n        uncompressedLength = data.readUInt32LE(8);\n        data = data.slice(12);\n      } else {\n        const view = new DataView(data.buffer);\n        this.highStart = view.getUint32(0, true);\n        this.errorValue = view.getUint32(4, true);\n        uncompressedLength = view.getUint32(8, true);\n        data = data.subarray(12);\n      }\n\n      // double inflate the actual trie data\n      data = inflate(data, new Uint8Array(uncompressedLength));\n      data = inflate(data, new Uint8Array(uncompressedLength));\n\n      // swap bytes from little-endian\n      swap32LE(data);\n\n      this.data = new Uint32Array(data.buffer);\n\n    } else {\n      // pre-parsed data\n      ({ data: this.data, highStart: this.highStart, errorValue: this.errorValue } = data);\n    }\n  }\n\n  get(codePoint) {\n    let index;\n    if ((codePoint < 0) || (codePoint > 0x10ffff)) {\n      return this.errorValue;\n    }\n\n    if ((codePoint < 0xd800) || ((codePoint > 0xdbff) && (codePoint <= 0xffff))) {\n      // Ordinary BMP code point, excluding leading surrogates.\n      // BMP uses a single level lookup.  BMP index starts at offset 0 in the index.\n      // data is stored in the index array itself.\n      index = (this.data[codePoint >> SHIFT_2] << INDEX_SHIFT) + (codePoint & DATA_MASK);\n      return this.data[index];\n    }\n\n    if (codePoint <= 0xffff) {\n      // Lead Surrogate Code Point.  A Separate index section is stored for\n      // lead surrogate code units and code points.\n      //   The main index has the code unit data.\n      //   For this function, we need the code point data.\n      index = (this.data[LSCP_INDEX_2_OFFSET + ((codePoint - 0xd800) >> SHIFT_2)] << INDEX_SHIFT) + (codePoint & DATA_MASK);\n      return this.data[index];\n    }\n\n    if (codePoint < this.highStart) {\n      // Supplemental code point, use two-level lookup.\n      index = this.data[(INDEX_1_OFFSET - OMITTED_BMP_INDEX_1_LENGTH) + (codePoint >> SHIFT_1)];\n      index = this.data[index + ((codePoint >> SHIFT_2) & INDEX_2_MASK)];\n      index = (index << INDEX_SHIFT) + (codePoint & DATA_MASK);\n      return this.data[index];\n    }\n\n    return this.data[this.data.length - DATA_GRANULARITY];\n  }\n}\n\nmodule.exports = UnicodeTrie;","const isBigEndian = (new Uint8Array(new Uint32Array([0x12345678]).buffer)[0] === 0x12);\n\nconst swap = (b, n, m) => {\n  let i = b[n];\n  b[n] = b[m];\n  b[m] = i;\n};\n\nconst swap32 = array => {\n  const len = array.length;\n  for (let i = 0; i < len; i += 4) {\n    swap(array, i, i + 3);\n    swap(array, i + 1, i + 2);\n  }\n};\n\nconst swap32LE = array => {\n  if (isBigEndian) {\n    swap32(array);\n  }\n};\n\nmodule.exports = {\n  swap32LE: swap32LE\n};\n","import split from 'graphemesplit';\n\nconst whitespaceRegex = /^\\s+$/;\nconst nonWordRegex = /^[`~!@#$%^&*()\\-=_+{}[\\]\\|\\\\;':\",./<>?]+$/;\nconst sortKind = {\n  insertOrder: \"insertOrder\",\n  bestMatch: \"bestMatch\"\n}; // the default options, which will be used for any unset option\n\nconst defaultOptions = {\n  keySelector: s => s,\n  threshold: .6,\n  ignoreCase: true,\n  ignoreSymbols: true,\n  normalizeWhitespace: true,\n  returnMatchData: false,\n  useDamerau: true,\n  useSellers: true,\n  sortBy: sortKind.bestMatch\n};\n\nconst noop = () => {};\n\nconst arrayWrap = item => item instanceof Array ? item : [item]; // return normalized string, with map included\n\n\nfunction normalize(string, options) {\n  const lower = options.ignoreCase ? string.toLocaleLowerCase() : string; // track transformations\n\n  const normal = [];\n  const map = [];\n  let lastWasWhitespace = true;\n  let length = 0;\n\n  for (const grapheme of split(lower)) {\n    whitespaceRegex.lastIndex = 0;\n    nonWordRegex.lastIndex = 0;\n\n    if (options.normalizeWhitespace && whitespaceRegex.test(grapheme)) {\n      if (!lastWasWhitespace) {\n        normal.push(\" \");\n        map.push(length);\n        lastWasWhitespace = true;\n      }\n    } else if (!(options.ignoreSymbols && nonWordRegex.test(grapheme))) {\n      normal.push(grapheme.normalize());\n      map.push(length);\n      lastWasWhitespace = false;\n    }\n\n    length += grapheme.length;\n  } // add the end of the string\n\n\n  map.push(string.length);\n\n  while (normal[normal.length - 1] === \" \") {\n    normal.pop();\n    map.pop();\n  }\n\n  return {\n    original: string,\n    normal,\n    map\n  };\n} // translates a match to the original string\n\n\nfunction denormalizeMatchPosition(match, map) {\n  return {\n    index: map[match.start],\n    length: map[match.end + 1] - map[match.start]\n  };\n} // walks back up the matrix to find the match index and length\n\n\nfunction walkBack(rows, scoreIndex) {\n  if (scoreIndex === 0) {\n    return {\n      index: 0,\n      length: 0\n    };\n  }\n\n  let start = scoreIndex;\n\n  for (let i = rows.length - 2; i > 0 && start > 1; i--) {\n    const row = rows[i];\n    start = row[start] < row[start - 1] ? start : start - 1;\n  }\n\n  return {\n    start: start - 1,\n    end: scoreIndex - 1\n  };\n} // walkback is a noop for non-sellers, but should still return an object\n\n\nfunction noopWalkback() {\n  return {\n    start: 0,\n    end: 0\n  };\n}\n\nconst levUpdateScore = () => true;\n\nconst sellersUpdateScore = (cur, min) => cur < min;\n\nfunction getLevScore(rows, length) {\n  const lastRow = rows[rows.length - 1];\n  const lastCell = lastRow[length - 1];\n  const scoreLength = Math.max(rows.length, length);\n  return {\n    score: 1 - lastCell / (scoreLength - 1),\n    scoreIndex: length - 1\n  };\n}\n\nfunction getSellersScore(rows, length) {\n  // search term was empty string, return perfect score\n  if (rows.length === 1) {\n    return {\n      score: 1,\n      scoreIndex: 0\n    };\n  }\n\n  const lastRow = rows[rows.length - 1];\n  let minValue = lastRow[0];\n  let minIndex = 0;\n\n  for (let i = 1; i < length; i++) {\n    const val = lastRow[i];\n\n    if (val < minValue) {\n      minValue = val;\n      minIndex = i;\n    }\n  }\n\n  return {\n    score: 1 - minValue / (rows.length - 1),\n    scoreIndex: minIndex\n  };\n}\n\nfunction initLevRows(rowCount, columnCount) {\n  const rows = new Array(rowCount);\n\n  for (let i = 0; i < rowCount; i++) {\n    rows[i] = new Array(columnCount);\n    rows[i][0] = i;\n  }\n\n  for (let i = 0; i < columnCount; i++) {\n    rows[0][i] = i;\n  }\n\n  return rows;\n}\n\nfunction initSellersRows(rowCount, columnCount) {\n  const rows = new Array(rowCount);\n  rows[0] = new Array(columnCount).fill(0);\n\n  for (let i = 1; i < rowCount; i++) {\n    rows[i] = new Array(columnCount);\n    rows[i][0] = i;\n  }\n\n  return rows;\n} // the content of the innermost loop of levenshtein\n\n\nfunction levCore(term, candidate, rows, i, j) {\n  const rowA = rows[i];\n  const rowB = rows[i + 1];\n  const cost = term[i] === candidate[j] ? 0 : 1;\n  let m;\n  let min = rowB[j] + 1; // insertion\n\n  if ((m = rowA[j + 1] + 1) < min) min = m; // deletion\n\n  if ((m = rowA[j] + cost) < min) min = m; // substitution\n\n  rowB[j + 1] = min;\n} // runtime complexity: O(mn) where m and n are the lengths of term and candidate, respectively\n// Note: this method only runs on a single column\n\n\nfunction levenshtein(term, candidate, rows, j) {\n  for (let i = 0; i < term.length; i++) {\n    levCore(term, candidate, rows, i, j);\n  }\n} // has all the runtime characteristics of the above, but punishes transpositions less,\n// resulting in better tolerance to those types of typos\n// Note: this method only runs on a single column\n\n\nfunction damerauLevenshtein(term, candidate, rows, j) {\n  // if j === 0, we can't check for transpositions,\n  // so use normal levenshtein instead\n  if (j === 0) {\n    levenshtein(term, candidate, rows, j);\n    return;\n  } // for i === 0, we also can't check for transpositions, so calculate\n  // the first row using normal levenshtein as well\n\n\n  if (term.length > 0) {\n    levCore(term, candidate, rows, 0, j);\n  }\n\n  for (let i = 1; i < term.length; i++) {\n    const rowA = rows[i - 1];\n    const rowB = rows[i];\n    const rowC = rows[i + 1];\n    const cost = term[i] === candidate[j] ? 0 : 1;\n    let m; // insertion\n\n    let min = rowC[j] + 1; // deletion\n\n    if ((m = rowB[j + 1] + 1) < min) min = m; // substitution\n\n    if ((m = rowB[j] + cost) < min) min = m; // transposition\n\n    if (term[i] === candidate[j - 1] && term[i - 1] === candidate[j] && (m = rowA[j - 1] + cost) < min) min = m;\n    rowC[j + 1] = min;\n  }\n} // method for creating a trie from search candidates\n// using a trie can significantly improve search time\n\n\nfunction trieInsert(trie, string, item) {\n  let walker = trie;\n\n  for (let i = 0; i < string.length; i++) {\n    const char = string[i]; // add child node if not already present\n\n    if (walker.children[char] == null) {\n      walker.children[char] = {\n        children: {},\n        candidates: [],\n        depth: 0\n      };\n    } // log max depth of this subtree\n\n\n    walker.depth = Math.max(walker.depth, string.length - i); // step into child node\n\n    walker = walker.children[char];\n  }\n\n  walker.candidates.push(item);\n} // transforms a list of candidates into objects with normalized search keys,\n// and inserts them into a trie\n// the keySelector is used to pick strings from an object to search by\n\n\nfunction createSearchTrie(trie, index, items, options) {\n  for (const item of items) {\n    const candidates = arrayWrap(options.keySelector(item)).map((key, keyIndex) => ({\n      index,\n      keyIndex,\n      item,\n      normalized: normalize(key, options)\n    }));\n    index++;\n\n    for (const candidate of candidates) {\n      trieInsert(trie, candidate.normalized.normal, candidate);\n    }\n  }\n} // scored item comparator\n\n\nfunction compareItemsBestScore(a, b) {\n  // highest priority is raw levenshtein score\n  const scoreDiff = b.score - a.score;\n\n  if (scoreDiff !== 0) {\n    return scoreDiff;\n  } // ties are broken by earlier match positions\n\n\n  const matchPosDiff = a.match.start - b.match.start;\n\n  if (matchPosDiff !== 0) {\n    return matchPosDiff;\n  } // prioritize earlier keys\n\n\n  const keyIndexDiff = a.keyIndex - b.keyIndex;\n\n  if (keyIndexDiff !== 0) {\n    return keyIndexDiff;\n  } // lastly, break ties by preferring the closer length match\n\n\n  const lengthDiff = a.lengthDiff - b.lengthDiff;\n\n  if (lengthDiff !== 0) {\n    return lengthDiff;\n  } // if all else fails, resort to insertion order\n\n\n  return compareItemsInsertOrder(a, b);\n}\n\nfunction compareItemsInsertOrder(a, b) {\n  return a.index - b.index;\n}\n\nfunction getCompareFunc(sortBy) {\n  switch (sortBy) {\n    case sortKind.bestMatch:\n      return compareItemsBestScore;\n\n    case sortKind.insertOrder:\n      return compareItemsInsertOrder;\n\n    default:\n      throw new Error(`unknown sortBy method ${sortBy}`);\n  }\n} // dedupes and adds results to the results list/map\n\n\nfunction addResult(results, resultMap, candidate, score, match, lengthDiff, compareItems) {\n  const scoredItem = {\n    item: candidate.item,\n    normalized: candidate.normalized,\n    score,\n    match,\n    index: candidate.index,\n    keyIndex: candidate.keyIndex,\n    lengthDiff\n  };\n\n  if (resultMap[candidate.index] == null) {\n    resultMap[candidate.index] = results.length;\n    results.push(scoredItem);\n  } else if (compareItems(scoredItem, results[resultMap[candidate.index]]) < 0) {\n    results[resultMap[candidate.index]] = scoredItem;\n  }\n}\n\nconst getLevLength = Math.max;\n\nconst getSellersLength = termLength => termLength; // skip any subtrees for which it is impossible to score >= threshold\n\n\nfunction levShouldContinue(node, pos, term, threshold, sValue) {\n  // earliest point (length) at which sValue could return to 0\n  const p1 = pos + sValue; // point (length) at which string lengths would match\n\n  const p2 = Math.min(term.length, pos + node.depth + 1); // the best score possible is the string which minimizes the value\n  // max(sValue, strLenDiff), which is always halfway between p1 and p2\n\n  const length = Math.ceil((p1 + p2) / 2);\n  const bestPossibleValue = length - p2;\n  return 1 - bestPossibleValue / length >= threshold;\n}\n\nfunction sellersShouldContinue(node, _, term, threshold, sValue, lastValue) {\n  const bestPossibleValue = Math.min(sValue, lastValue - (node.depth + 1));\n  return 1 - bestPossibleValue / term.length >= threshold;\n} // (pseudo) recursively walk the trie\n\n\nfunction searchRecurse(trie, term, scoreMethods, rows, results, resultMap, options) {\n  const stack = [];\n\n  for (const key in trie.children) {\n    const node = trie.children[key];\n    stack.push([node, 1, key, 0, term.length]);\n  }\n\n  const acc = new Array(trie.depth);\n\n  while (stack.length !== 0) {\n    const [node, len, char, si, sv] = stack.pop();\n    acc[len - 1] = char; // build rows\n\n    scoreMethods.score(term, acc, rows, len - 1); // track best score and position\n\n    const lastIndex = len;\n    const lastValue = rows[rows.length - 1][lastIndex];\n    let sIndex = si,\n        sValue = sv;\n\n    if (scoreMethods.shouldUpdateScore(lastValue, sv)) {\n      sIndex = lastIndex;\n      sValue = lastValue;\n    } // insert results\n\n\n    if (node.candidates.length > 0) {\n      const length = scoreMethods.getLength(term.length, len);\n      const score = 1 - sValue / length;\n\n      if (score >= options.threshold) {\n        const match = walkBack(rows, sIndex);\n        const lengthDiff = Math.abs(len - term.length);\n\n        for (const candidate of node.candidates) {\n          addResult(results, resultMap, candidate, score, match, lengthDiff, scoreMethods.compareItems);\n        }\n      }\n    } // recurse for children\n\n\n    for (const key in node.children) {\n      const child = node.children[key];\n\n      if (scoreMethods.shouldContinue(child, len, term, options.threshold, sValue, lastValue)) {\n        stack.push([child, len + 1, key, sIndex, sValue]);\n      }\n    }\n  }\n} // the core match finder: returns a sorted, filtered list of matches\n// this does not normalize input, requiring users to normalize themselves\n\n\nfunction searchCore(term, trie, options) {\n  const initMethod = options.useSellers ? initSellersRows : initLevRows;\n  const scoreMethods = {\n    score: options.useDamerau ? damerauLevenshtein : levenshtein,\n    getLength: options.useSellers ? getSellersLength : getLevLength,\n    shouldUpdateScore: options.useSellers ? sellersUpdateScore : levUpdateScore,\n    shouldContinue: options.useSellers ? sellersShouldContinue : levShouldContinue,\n    walkBack: options.useSellers ? walkBack : noopWalkback,\n    compareItems: getCompareFunc(options.sortBy)\n  }; // walk the trie, scoring and storing the candidates\n\n  const resultMap = {};\n  const results = [];\n  const rows = initMethod(term.length + 1, trie.depth + 1);\n\n  if (options.threshold <= 0 || term.length === 0) {\n    for (const candidate of trie.candidates) {\n      addResult(results, resultMap, candidate, 0, {\n        index: 0,\n        length: 0\n      }, term.length, scoreMethods.compareItems);\n    }\n  }\n\n  searchRecurse(trie, term, scoreMethods, rows, results, resultMap, options);\n  const sorted = results.sort(scoreMethods.compareItems);\n\n  if (options.returnMatchData) {\n    const denormalize = options.useSellers ? denormalizeMatchPosition : noop;\n    return sorted.map(candidate => ({\n      item: candidate.item,\n      original: candidate.normalized.original,\n      key: candidate.normalized.normal.join(\"\"),\n      score: candidate.score,\n      match: denormalize(candidate.match, candidate.normalized.map)\n    }));\n  }\n\n  return sorted.map(candidate => candidate.item);\n} // wrapper for exporting sellers while allowing options to be passed in\n\n\nfunction fuzzy(term, candidate, options) {\n  options = { ...defaultOptions,\n    ...options\n  };\n  const initMethod = options.useSellers ? initSellersRows : initLevRows;\n  const scoreMethod = options.useDamerau ? damerauLevenshtein : levenshtein;\n  const getScore = options.useSellers ? getSellersScore : getLevScore;\n  term = normalize(term, options).normal;\n  const normalized = normalize(candidate, options);\n  const rows = initMethod(term.length + 1, normalized.normal.length + 1);\n\n  for (let j = 0; j < normalized.normal.length; j++) {\n    scoreMethod(term, normalized.normal, rows, j);\n  }\n\n  const scoreResult = getScore(rows, normalized.normal.length + 1);\n  return options.returnMatchData ? {\n    item: candidate,\n    original: normalized.original,\n    key: normalized.normal.join(\"\"),\n    score: scoreResult.score,\n    match: options.useSellers ? denormalizeMatchPosition(walkBack(rows, scoreResult.scoreIndex), normalized.map) : noop()\n  } : scoreResult.score;\n} // simple one-off search. Useful if you don't expect to use the same candidate list again\n\nfunction search(term, candidates, options) {\n  options = { ...defaultOptions,\n    ...options\n  };\n  const trie = {\n    children: {},\n    candidates: [],\n    depth: 0\n  };\n  createSearchTrie(trie, 0, candidates, options);\n  return searchCore(normalize(term, options).normal, trie, options);\n} // class that improves performance of searching the same set multiple times\n// normalizes the strings and caches the result for future calls\n\nclass Searcher {\n  constructor(candidates, options) {\n    this.options = Object.assign({}, defaultOptions, options);\n    this.trie = {\n      children: {},\n      candidates: [],\n      depth: 0\n    };\n    createSearchTrie(this.trie, 0, candidates, this.options);\n    this.count = candidates.length;\n  }\n\n  add(...candidates) {\n    createSearchTrie(this.trie, this.count, candidates, this.options);\n    this.count += candidates.length;\n  }\n\n  search(term, options) {\n    options = Object.assign({}, this.options, options);\n    return searchCore(normalize(term, this.options).normal, this.trie, options);\n  }\n\n}\n\nexport { Searcher, fuzzy, search, sortKind };\n","__webpack_require__.h = function() { return \"f315989fe7f2ed006e14\"; }","__webpack_require__.hmd = function(module) {\n\tmodule = Object.create(module);\n\tif (!module.children) module.children = [];\n\tObject.defineProperty(module, 'exports', {\n\t\tenumerable: true,\n\t\tset: function() {\n\t\t\tthrow new Error('ES Modules may not assign module.exports or exports.*, Use ESM export syntax, instead: ' + module.id);\n\t\t}\n\t});\n\treturn module;\n};"],"names":["search","fastSearch","useState","createContext","useContext","MAX_RESULTS","StateContext","getType","obj","lib","prop","$$typeof","toUpperCase","getDocLink","console","log","module","getDocModule","activeStore","s","split","flatten","out","push","text","type","docLink","DataTabProvider","children","action","setAction","setActiveStore","activeFunction","setActiveFunction","allData","wp","stores","i","Object","keys","length","key","store","storeNames","map","name","k","concat","data","select","dispatch","keyword","results","ignoreCase","keySelector","splice","useDataTab","context","undefined","Error"],"sourceRoot":""}